{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143f59c7",
   "metadata": {},
   "source": [
    "# Mock interview Seite für Studenten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaba01a",
   "metadata": {},
   "source": [
    "## Für dieses Interview wirst du mit dem folgenden Datensatz arbeiten. Schau ihn dir gerne in Ruhe an, um dich damit vertraut zu machen. \n",
    "- loans_modified.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49428f86",
   "metadata": {},
   "source": [
    " ## Ziel des Interviews:\n",
    " - Erstelle ein Modell zur Analyse von Darlehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fbfdb8",
   "metadata": {},
   "source": [
    "# Schritte zur Vorbereitung:\n",
    "- 1. Mach dich mit den Daten vertraut.\n",
    "- 2. Versuch, ein Modell zu erstellen.\n",
    "- 3. Wir empfehlen dir, ein Notebook bereitzuhalten, um während des Interviews Notizen zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed8ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** DATEI LADEN **********\n",
      "Lokale Umgebung erkannt. Es öffnet sich ein Dateiauswahlfenster.\n",
      "\n",
      "Die Datei '/Users/cristallagus/Desktop/GitHub/Mock Interviwe 07.09.2025/loans_modified.csv' wurde erfolgreich geladen.\n"
     ]
    }
   ],
   "source": [
    "# ⚙️ Laden von CSV-Dateien in Colab/VSCode-Umgebung\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tkinter import filedialog\n",
    "from tkinter import Tk\n",
    "\n",
    "# Einstellungen\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Erkennung der Umgebung (Google Colab oder lokal)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    COLAB_ENV = True\n",
    "except ImportError:\n",
    "    COLAB_ENV = False\n",
    "\n",
    "# ====== DATEI LADEN ======\n",
    "print('*' * 10, 'DATEI LADEN', '*' * 10)\n",
    "\n",
    "try:\n",
    "    if COLAB_ENV:\n",
    "        # Code für Google Colab\n",
    "        print(\"Google Colab Umgebung erkannt. Bitte Datei hochladen.\")\n",
    "        uploaded = files.upload()\n",
    "        file_name = list(uploaded.keys())[0]\n",
    "        print(f\"\\nDie Datei '{file_name}' wurde erfolgreich hochgeladen und steht nun zur Verfügung.\")\n",
    "        df = pd.read_csv(file_name)\n",
    "    else:\n",
    "        # Code für lokale Umgebung mit Tkinter-Dateiauswahlfenster\n",
    "        print(\"Lokale Umgebung erkannt. Es öffnet sich ein Dateiauswahlfenster.\")\n",
    "        \n",
    "        # Erstellen eines Tkinter-Root-Fensters und Ausblenden\n",
    "        root = Tk()\n",
    "        root.withdraw() \n",
    "        \n",
    "        # Öffnen des Dateidialogs und Abrufen des Pfades\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Wählen Sie Ihre CSV-Datei\",\n",
    "            filetypes=((\"CSV-Dateien\", \"*.csv\"), (\"Alle Dateien\", \"*.*\"))\n",
    "        )\n",
    "        \n",
    "        if file_path:\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"\\nDie Datei '{file_path}' wurde erfolgreich geladen.\")\n",
    "        else:\n",
    "            print(\"Keine Datei ausgewählt.\")\n",
    "            df = None\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Ein Fehler ist aufgetreten: {e}\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d986d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** DATEN LADEN **********\n",
      "Daten erfolgreich geladen! DataFrame-Größe: (563, 13)\n",
      "\n",
      "Erste 5 Zeilen des geladenen DataFrames zur Überprüfung:\n",
      "    loan_id gender married dependents     education self_employed  applicant_income  coapplicant_income  loan_amount  loan_amount_term  credit_history property_area  loan_status\n",
      "0  LP001003   Male     Yes          1      Graduate            No            4583.0              1508.0        128.0             360.0             1.0         Rural          0.0\n",
      "1  LP001005   Male     Yes          0      Graduate           NaN            3000.0                 0.0         66.0             360.0             1.0         Urban          1.0\n",
      "2  LP001006   Male     Yes          0  Not Graduate            No            2583.0              2358.0        120.0             360.0             1.0         Urban          1.0\n",
      "3  LP001008   Male      No          0      Graduate            No            6000.0                 0.0        141.0             360.0             1.0         Urban          1.0\n",
      "4  LP001011   Male     Yes          2      Graduate           Yes            5417.0              4196.0        267.0             360.0             1.0         Urban          1.0\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# ⚙️ DataFrames als CSV-Datei in df benennen\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "print('*' * 10, 'DATEN LADEN', '*' * 10)\n",
    "\n",
    "df = pd.read_csv('loans_modified.csv')\n",
    "\n",
    "# Erfolgsnachweis: Ausgabe der Dateninformationen\n",
    "print(f\"Daten erfolgreich geladen! DataFrame-Größe: {df.shape}\")\n",
    "print(\"\\nErste 5 Zeilen des geladenen DataFrames zur Überprüfung:\")\n",
    "print(df.head().to_string())\n",
    "\n",
    "print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b367f769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** KONSOLIDIERTE DATENQUALITÄTS-ANALYSE **********\n",
      "Form (Zeilen, Spalten): (563, 13) | Duplikate: 25\n",
      "--------------------------------------------------\n",
      "                Spalte Semantischer Typ Ursprünglicher Datentyp  Einzigartige Werte  Fehlende Werte (Anzahl)  Fehlende Werte (%)    Min 25% (Q1)  Median 75% (Q3)      Max Skewness Ausreißer (IQR-Anzahl)\n",
      "0              loan_id               ID                  object                 512                       29                5.15      -        -       -        -        -        -                      -\n",
      "1               gender    Text (Gender)                  object                   2                       29                5.15      -        -       -        -        -        -                      -\n",
      "2              married          Boolean                  object                   2                       19                3.37      -        -       -        -        -        -                      0\n",
      "3           dependents           object                  object                   4                       32                5.68      -        -       -        -        -        -                      -\n",
      "4            education           object                  object                   2                       22                3.91      -        -       -        -        -        -                      -\n",
      "5        self_employed          Boolean                  object                   2                       34                6.04      -        -       -        -        -        -                      0\n",
      "6     applicant_income          float64                 float64                 429                       26                4.62  150.0   2894.0  3762.0   5818.0  81000.0     6.74                     46\n",
      "7   coapplicant_income          float64                 float64                 252                       34                6.04    0.0      0.0  1250.0   2333.0  41667.0      7.3                     18\n",
      "8          loan_amount          float64                 float64                 194                       30                5.33    9.0    100.0   128.0    172.0    650.0     2.43                     32\n",
      "9     loan_amount_term          float64                 float64                  10                       28                4.97   12.0    360.0   360.0    360.0    480.0    -2.43                     75\n",
      "10      credit_history          float64                 float64                   2                       22                3.91    0.0      1.0     1.0      1.0      1.0    -2.32                     66\n",
      "11       property_area           object                  object                   3                       21                3.73      -        -       -        -        -        -                      -\n",
      "12         loan_status          float64                 float64                   2                       28                4.97    0.0      0.0     1.0      1.0      1.0    -0.97                      0\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from typing import Dict, List, Callable, Union\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# HILFSFUNKTIONEN FÜR SEMANTISCHE MUSTER-ERKENNUNG (AUS IHREM VORSCHLAG)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# NOTE: generate_cleaning_muster wird ignoriert, da keine Vorschläge gewünscht sind\n",
    "def generate_cleaning_muster(column: str, semantic_type: str) -> str:\n",
    "    # Nur ein Platzhalter, da keine Code-Ausgabe gewünscht ist\n",
    "    return \"\"\n",
    "\n",
    "def analyze_semantic_type_v3(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analysiert die semantischen Datentypen der Spalten in einem DataFrame.\n",
    "    Die interne Logik zur Typ-Erkennung wurde von Ihrem bereitgestellten Muster übernommen.\n",
    "    \"\"\"\n",
    "    SEMANTIC_HINTS_PRIORITY: Dict[str, Dict[str, Union[set, Callable]]] = {\n",
    "        'ID': {\n",
    "            'keywords': {'_id', 'session_id', 'trip_id', 'user_id', 'unique_id', 'kundennummer', 'bestellnr', 'order_id', 'artikelnummer'},\n",
    "            'validation_func': lambda series: ((series.dropna().astype(str).apply(len) >= 5).any())\n",
    "        },\n",
    "        'Datum/Zeit': {\n",
    "            'keywords': {'datum', 'zeit', 'date', 'time', 'start', 'end', 'birthdate', 'signup_date', 'check_in', 'check_out', 'departure', 'return', 'geburtstag', 'timestamp', 'creation_date', 'modified_date', 'erstellt'},\n",
    "            'validation_func':lambda series: ((series.dropna().nunique() == 12 or series.dropna().nunique() == 31) or (series.dropna().apply(lambda x: isinstance(x, str)).all() and (pd.to_datetime(series.dropna(), errors='coerce').notna().all() or (series.dropna().astype(str).str.contains(r'[-_/]', na=False).any() and series.dropna().astype(str).str.contains(r'\\d{4}', na=False).any()))))\n",
    "        },\n",
    "        'Geometrisch': {\n",
    "            'keywords': {'geom', 'geometry', 'shape', 'wkt', 'geojson', 'coordinates', 'location_data'},\n",
    "            'validation_func': lambda series: (series.dropna().astype(str).str.contains(r'^(POINT|LINESTRING|POLYGON|MULTIPOINT|MULTILINESTRING|MULTIPOLYGON)\\s*\\(', regex=True, na=False).any() or series.dropna().astype(str).str.contains(r'{\"type\":\\s*\"(Point|LineString|Polygon|MultiPoint|MultiLineString|MultiPolygon)\"', regex=True, na=False).any())\n",
    "        },\n",
    "    }\n",
    "    SEMANTIC_HINTS_TEXT: Dict[str, Dict[str, Union[set, Callable]]] = {\n",
    "        'Text (Kategorisch)': {\n",
    "            'keywords': {'city', 'country', 'länder', 'region', 'state', 'bundesland', 'zip', 'plz'},\n",
    "            'validation_func': lambda series: series.dropna().nunique() >= 2 and (pd.api.types.is_string_dtype(series.dropna()) or isinstance(series.dropna().dtype, pd.CategoricalDtype))\n",
    "        },\n",
    "         'Text (Gender)': {\n",
    "            'keywords': {'geschlecht', 'typ', 'category', 'art', 'gender'},\n",
    "            'validation_func': lambda series: series.dropna().nunique() >= 2 and (pd.api.types.is_string_dtype(series.dropna()) or isinstance(series.dropna().dtype, pd.CategoricalDtype))\n",
    "        },\n",
    "        'Text (object)': {\n",
    "            'keywords': {'airport', 'destination', 'origin', 'heimat', 'status'},\n",
    "            'validation_func': lambda series: series.dropna().nunique() >= 2 and (pd.api.types.is_string_dtype(series.dropna()) or isinstance(series.dropna().dtype, pd.CategoricalDtype))\n",
    "        },\n",
    "        'Text (Freitext)': {\n",
    "            'keywords': {'name', 'hotel', 'airline', 'beschreibung', 'kommentar', 'nachricht', 'adresse'},\n",
    "            'validation_func': lambda series: pd.api.types.is_string_dtype(series.dropna()) or isinstance(series.dropna().dtype, pd.CategoricalDtype)\n",
    "        },\n",
    "    }\n",
    "    SEMANTIC_HINTS_NUMERIC: Dict[str, Dict[str, Union[set, Callable]]] = {\n",
    "        'Boolean(NaN)': {\n",
    "            'keywords': {'is_invalid','missing', 'is_missing', 'has_value', 'exists', 'is_null', 'is_na', 'isnan', 'filled','is_outlier'},\n",
    "            'validation_func': lambda series: (series.dropna().nunique() >= 1) and (pd.api.types.is_bool_dtype(series.dropna()) or set(series.dropna().astype(str).str.lower().str.strip().unique()).issubset({'true', 'false', '1', '0', 'ja', 'nein', 'yes', 'no', 't', 'f', 'wahr', 'falsch'}))\n",
    "        },\n",
    "        'Boolean': {\n",
    "            'keywords': {'self_employed','is_weekend_trip', 'boolean', 'bool', 'booked', 'married', 'cancellation', 'children','discount', 'flight_booked', 'hotel_booked', 'return_flight_booked', 'is_cancelled'},\n",
    "            'validation_func': lambda series: (series.dropna().nunique() == 2) and (pd.api.types.is_bool_dtype(series.dropna()) or set(series.dropna().astype(str).str.lower().str.strip().unique()).issubset({'true', 'false', '1', '0', 'ja', 'nein', 'yes', 'no', 't', 'f', 'wahr', 'falsch'}))\n",
    "        },\n",
    "        'Float (Geografisch)': {\n",
    "            'keywords': {'lat', 'lon', 'latitude', 'longitude'},\n",
    "            'validation_func': lambda series: pd.to_numeric(series.dropna(), errors='coerce').notna().all() and (pd.to_numeric(series.dropna(), errors='coerce').astype(str).str.count(r'\\.').all() or pd.api.types.is_float_dtype(series.dropna()))\n",
    "        },\n",
    "        'Float (Prozentsatz)': {\n",
    "            'keywords': {'percent', 'pct', 'rate', 'discount', '%'},\n",
    "            'validation_func': lambda series: (series.dropna().nunique() > 2) and ((pd.to_numeric(series.dropna().astype(str).str.replace('%', ''), errors='coerce').dropna().between(0, 1).all() or pd.to_numeric(series.dropna().astype(str).str.replace('%', ''), errors='coerce').dropna().between(0, 100).all()) or (pd.to_numeric(series.dropna().astype(str).str.replace('%', ''), errors='coerce').notna().all() and series.dropna().astype(str).str.replace('%', '').str.replace(',', '.').str.match(r'^\\d{1,3}(\\.\\d{1,3})?$').all()))\n",
    "        },\n",
    "        'Float (Waehrung)': {\n",
    "            'keywords': {'preis', 'kosten', 'betrag', 'dollar', 'euro', 'yen', 'usd', 'eur', 'fare','chf', 'gbp', 'sek', 'jpy', '€', '£', '$'},\n",
    "            'validation_func': lambda series: (pd.api.types.is_numeric_dtype(series.dropna()) or pd.to_numeric(series.dropna().str.replace(',', '.'), errors='coerce').notna().all()) and series.dropna().nunique() > 2\n",
    "        },\n",
    "        'Integer': {\n",
    "            'keywords': {'_time_days','_duration_days','anzahl', 'menge', 'stueck', 'stk', 'count', 'qty', 'seats', 'rooms', 'nights', 'bags', 'clicks', 'nummer', 'nr', 'quantity', 'val', 'rating'},\n",
    "            'validation_func': lambda series: (series.dropna().nunique() > 2) and pd.to_numeric(series.dropna(), errors='coerce').notna().all() and (pd.to_numeric(series.dropna(), errors='coerce').dropna().apply(lambda x: x.is_integer() if isinstance(x, float) else True).all())\n",
    "        }\n",
    "    }\n",
    "\n",
    "    results: List[Dict[str, str]] = []\n",
    "    hint_categories = [SEMANTIC_HINTS_PRIORITY, SEMANTIC_HINTS_TEXT, SEMANTIC_HINTS_NUMERIC]\n",
    "    SEMANTIC_HINTS_NUMERIC_ORDERED: List[str] = ['Boolean(NaN)','Boolean', 'Float (Geografisch)', 'Float (Prozentsatz)', 'Float (Waehrung)', 'Integer']\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "        for column in df.columns:\n",
    "            original_dtype: str = str(df[column].dtype)\n",
    "            semantic_type: str = original_dtype\n",
    "            column_lower: str = column.lower()\n",
    "            found_match: bool = False\n",
    "\n",
    "            for hint_group in hint_categories:\n",
    "                if found_match:\n",
    "                    break\n",
    "                if hint_group is SEMANTIC_HINTS_NUMERIC:\n",
    "                    for sem_type in SEMANTIC_HINTS_NUMERIC_ORDERED:\n",
    "                        hints = hint_group[sem_type]\n",
    "                        name_match = any(keyword in column_lower for keyword in hints['keywords'])\n",
    "                        content_valid = False\n",
    "                        try:\n",
    "                            content_valid = hints['validation_func'](df[column])\n",
    "                        except Exception:\n",
    "                            pass\n",
    "\n",
    "                        if name_match and content_valid:\n",
    "                            semantic_type = sem_type\n",
    "                            found_match = True\n",
    "                            break\n",
    "                else:\n",
    "                    for sem_type, hints in hint_group.items():\n",
    "                        name_match = any(keyword in column_lower for keyword in hints['keywords'])\n",
    "                        content_valid = False\n",
    "                        try:\n",
    "                            content_valid = hints['validation_func'](df[column])\n",
    "                        except Exception:\n",
    "                            pass\n",
    "\n",
    "                        if name_match and content_valid:\n",
    "                            semantic_type = sem_type\n",
    "                            found_match = True\n",
    "                            break\n",
    "\n",
    "            results.append({\n",
    "                'Spalte': column,\n",
    "                'Semantischer Typ': semantic_type,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# HAUPT-MUSTER FÜR KONSOLIDIERTE ANZEIGE (INKL. SEMANTIK, OHNE VORSCHLÄGE)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def muster_df_consolidated_view(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Führt eine konsolidierte Datenqualitäts-Analyse durch, inklusive semantischer\n",
    "    Typ-Erkennung, und gibt diese in einer einzigen Tabelle aus, ohne\n",
    "    Bereinigungsvorschläge.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Semantische Typ-Erkennung\n",
    "    df_sem_types = analyze_semantic_type_v3(df)\n",
    "    \n",
    "    # Dictionary zur Konsolidierung ALLER Metriken pro Spalte\n",
    "    consolidated_data: Dict[str, Dict[str, Union[str, float, int, None]]] = {}\n",
    "\n",
    "    # Initialisierung und Basis-Metriken\n",
    "    for col in df.columns:\n",
    "        sem_type_row = df_sem_types[df_sem_types['Spalte'] == col].iloc[0] if col in df_sem_types['Spalte'].values else {'Semantischer Typ': str(df[col].dtype)}\n",
    "        \n",
    "        consolidated_data[col] = {\n",
    "            'Spalte': col,\n",
    "            'Semantischer Typ': sem_type_row['Semantischer Typ'],\n",
    "            'Ursprünglicher Datentyp': str(df[col].dtype),\n",
    "            'Einzigartige Werte': df[col].nunique(),\n",
    "            'Fehlende Werte (Anzahl)': df[col].isnull().sum(),\n",
    "            'Fehlende Werte (%)': round(df[col].isnull().sum() / len(df) * 100, 2),\n",
    "            \n",
    "            # Statistische und ML-Metriken (Standardmäßig NaN)\n",
    "            'Min': np.nan, '25% (Q1)': np.nan, 'Median': np.nan, '75% (Q3)': np.nan, 'Max': np.nan,\n",
    "            'Skewness': np.nan,\n",
    "            'Ausreißer (IQR-Anzahl)': 0,\n",
    "        }\n",
    "\n",
    "    # 2. Numerische Metriken und ML-Analyse\n",
    "    # Spalten, die nach der semantischen Analyse als numerisch gelten könnten (inkl. Booleans)\n",
    "    numeric_relevant_types = {'Float (Geografisch)', 'Float (Prozentsatz)', 'Float (Waehrung)', 'Integer', 'Boolean', 'Boolean(NaN)'}\n",
    "    \n",
    "    for _, row in df_sem_types.iterrows():\n",
    "        column = row['Spalte']\n",
    "        semantic_type = row['Semantischer Typ']\n",
    "        series = df[column]\n",
    "\n",
    "        # Führe numerische Analysen nur für als numerisch erkannte Spalten durch\n",
    "        if semantic_type in numeric_relevant_types or pd.api.types.is_numeric_dtype(series):\n",
    "            try:\n",
    "                # Verwenden von to_numeric mit errors='coerce' ist sicherer für gemischte Typen\n",
    "                numeric_series = pd.to_numeric(series, errors='coerce').dropna()\n",
    "                \n",
    "                if not numeric_series.empty:\n",
    "                    q1, median, q3 = numeric_series.quantile([0.25, 0.5, 0.75])\n",
    "                    min_val = numeric_series.min()\n",
    "                    max_val = numeric_series.max()\n",
    "\n",
    "                    skewness = round(numeric_series.skew(), 2)\n",
    "                    \n",
    "                    Q1_o, Q3_o = numeric_series.quantile([0.25, 0.75])\n",
    "                    IQR = Q3_o - Q1_o\n",
    "                    lower_bound = Q1_o - 1.5 * IQR\n",
    "                    upper_bound = Q3_o + 1.5 * IQR\n",
    "                    outliers_count = ((numeric_series < lower_bound) | (numeric_series > upper_bound)).sum()\n",
    "                    \n",
    "                    consolidated_data[column].update({\n",
    "                        'Min': round(min_val, 2),\n",
    "                        '25% (Q1)': round(q1, 2),\n",
    "                        'Median': round(median, 2),\n",
    "                        '75% (Q3)': round(q3, 2),\n",
    "                        'Max': round(max_val, 2),\n",
    "                        'Skewness': skewness,\n",
    "                        'Ausreißer (IQR-Anzahl)': int(outliers_count)\n",
    "                    })\n",
    "            except Exception:\n",
    "                pass # Bleibt bei NaN, falls die Umwandlung fehlschlägt\n",
    "\n",
    "    # 3. KONSOLIDIERTE AUSGABE\n",
    "    \n",
    "    final_df = pd.DataFrame(list(consolidated_data.values()))\n",
    "    \n",
    "    # Spaltenreihenfolge für die Lesbarkeit anpassen\n",
    "    column_order = [\n",
    "        'Spalte', 'Semantischer Typ', 'Ursprünglicher Datentyp', 'Einzigartige Werte',\n",
    "        'Fehlende Werte (Anzahl)', 'Fehlende Werte (%)', \n",
    "        'Min', '25% (Q1)', 'Median', '75% (Q3)', 'Max', 'Skewness',\n",
    "        'Ausreißer (IQR-Anzahl)',\n",
    "    ]\n",
    "    final_df = final_df[[col for col in column_order if col in final_df.columns]]\n",
    "    \n",
    "    # NaN-Werte und 0-Werte für Nicht-Numerische durch \"-\" ersetzen\n",
    "    for stat_col in ['Min', '25% (Q1)', 'Median', '75% (Q3)', 'Max', 'Skewness']:\n",
    "        final_df[stat_col] = final_df[stat_col].apply(lambda x: '-' if pd.isna(x) else x)\n",
    "        \n",
    "    final_df['Ausreißer (IQR-Anzahl)'] = final_df.apply(\n",
    "        lambda row: '-' if row['Semantischer Typ'] not in numeric_relevant_types and not pd.api.types.is_numeric_dtype(df[row['Spalte']]) else int(row['Ausreißer (IQR-Anzahl)']) if row['Ausreißer (IQR-Anzahl)'] is not None else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "    # ====== FINALE AUSGABE ======\n",
    "    print('*' * 10, 'KONSOLIDIERTE DATENQUALITÄTS-ANALYSE', '*' * 10)\n",
    "    print(f\"Form (Zeilen, Spalten): {df.shape} | Duplikate: {df.duplicated().sum()}\")\n",
    "    print(\"-\" * 50)\n",
    "    # Ausgabe der finalen, konsolidierten Tabelle\n",
    "    print(final_df.to_string())\n",
    "    print('*' * 50)\n",
    "    # ============================\n",
    "\n",
    "# HAUPTTEIL DES SKRIPTS\n",
    "if 'df' in locals() and isinstance(df, pd.DataFrame):\n",
    "    muster_df_consolidated_view(df)\n",
    "else:\n",
    "    print(\"Bitte laden Sie Ihren Datensatz in einen Pandas DataFrame namens 'df'!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
